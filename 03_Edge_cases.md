# Handling ambiguity and conflict in annotation  
*Decision logic for cases that donâ€™t fit the rules*

---

### ğŸ¯ Why this block matters

No guideline covers 100% of cases.  
But **imprecise annotation** in an edge case can lead to **skewed training and costly model errors**.

This block gives annotators a structured way to act â€” not guess â€” when:

- tags overlap,  
- context is unclear,  
- or cultural differences create ambiguity.

---

### âš ï¸ Common types of edge cases

#### ğŸŒ€ 1. Overlapping categories  
Example: a sentence is both sarcastic and negatively toned.  
â†’ Which tag takes priority?

#### ğŸŒ 2. Cross-cultural or language-specific differences  
Example: a Russian idiom like â€œĞ¼Ğ¾Ñ Ñ…Ğ°Ñ‚Ğ° Ñ ĞºÑ€Ğ°Ñâ€ may read as neutral, ironic, or evasive depending on the reader.  
â†’ Should this be tagged as `idiom`, `irony`, or neither?

#### ğŸ§© 3. Lack of context  
Example: â€œThat was interesting.â€  
â†’ Is it positive? Sarcastic? Neutral? Do we mark it or skip it?

#### ğŸ”€ 4. Instruction vs. annotator intuition  
Example: a phrase is flagged as `offensive`, but might be a joke within a specific group.  
â†’ Follow the letter of the rule â€” or account for context?

---

### ğŸ§  Resolution strategies

#### 1. **Use decision trees, not gut feelings**  
Structured logic improves inter-annotator consistency and model alignment.

#### 2. **Flags are not failures**  
Using `ambiguous`, `cross-cultural`, or `requires-context` isnâ€™t weak â€”  
itâ€™s how we prevent silent model drift.

#### 3. **Separate whatâ€™s seen from whatâ€™s inferred**  
Even if a human can â€œsenseâ€ the tone, ask:  
â†’ *Will the model see it in the input â€” or hallucinate?*

---

### ğŸŒ³ How to build a decision tree

1. Identify the pain point:  
   Whatâ€™s unclear â€” semantics, tone, cultural anchor?

2. Build logical checkpoints:  
   â€œAre there clear markers?â€ â†’ â€œCan it be understood in isolation?â€ â†’ â€œIs it token-visible?â€

3. Each endpoint leads to:
- A specific tag  
- A fallback flag (`ambiguous`, `cross-cultural`, `requires-context`)  
- Or exclusion from annotation

---

### ğŸ” Example: irony decision tree

```plaintext
Are there explicit lexical irony markers?
  â””â”€ Yes â†’ irony.explicit
  â””â”€ No â†’
      Compare meaning vs. context:
        â””â”€ Contradiction is present but unprovable â†’ ambiguous
        â””â”€ Interpretation depends on cultural frame â†’ cross-cultural
        â””â”€ Meaning depends on external knowledge â†’ requires-context
